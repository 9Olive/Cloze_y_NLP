{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### NLTK Set up\n",
    "\n",
    "Follow [1.2 Getting Started with NLTK](https://www.nltk.org/book/ch01.html)\n",
    "\n",
    "A better reference: [NLP with Python](https://bagustris.github.io/nlp-python/index.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run once, or as many times as you need to configure which files you want access to. \n",
    "import nltk\n",
    "from nltk.util import ngrams\n",
    "# nltk.download()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "from tqdm import tqdm\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carga the CESS_ESP corpus. Vamos a entranar nuestro modelo\n",
    "training_corpus = nltk.corpus.cess_esp.words()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:11<00:00,  2.89s/it]\n"
     ]
    }
   ],
   "source": [
    "# Hagas los N-grams, por N=[2,3,4,5]\n",
    "N=[2,3,4,5]\n",
    "N_grams={\n",
    "    1:[],\n",
    "    2:[],\n",
    "    3:[],\n",
    "    4:[],\n",
    "    5:[]\n",
    "}\n",
    "\n",
    "# Tecnicamente, no necesitamos declarar las listas\n",
    "N_grams_cnt={}\n",
    "N_grams_freq={}\n",
    "\n",
    "for n in tqdm(N):\n",
    "    N_grams[n]=list(\n",
    "        ngrams(\n",
    "            training_corpus,\n",
    "            n\n",
    "        )\n",
    "    )\n",
    "    N_grams_cnt[n]=Counter(N_grams[n])\n",
    "    N_grams_cnt[f\"{n}_total_cnt\"]=sum(N_grams_cnt[n].values())\n",
    "    N_grams_freq[n]={\n",
    "        ngram: count / N_grams_cnt[f\"{n}_total_cnt\"] for ngram, count in N_grams_cnt[n].items()\n",
    "    }\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [12:54<00:00, 193.59s/it]\n"
     ]
    }
   ],
   "source": [
    "N_gram_mle={}\n",
    "N_gram_mle_str={}\n",
    "\n",
    "for n in tqdm(N):\n",
    "    N_gram_cache={} # no es el mismo cache del paper\n",
    "    N_gram_mle[n]={} # para gana los \n",
    "    N_gram_mle_str[n]={}\n",
    "    for gram in N_grams[n]:\n",
    "        if gram[0] in N_gram_cache.keys():\n",
    "            tkn_n_gram_cnt=N_gram_cache[gram[0]]\n",
    "        else:\n",
    "            grams_with_matching_first_word = [index for index, tup in enumerate(N_grams[n]) if gram[0]==tup[0]] # Gana los n-grams que lo tiene la primera palabra misma.\n",
    "            tkn_n_gram_cnt = N_gram_cache[gram[0]] = len(grams_with_matching_first_word) # contar los iguales\n",
    "        gram_str=\" \"\n",
    "        gram_str=gram_str.join(gram)\n",
    "        if n == 1:\n",
    "            N_gram_mle[n][gram]=round(N_grams_cnt[n][gram]/N_grams_cnt[f\"{n}_total_cnt\"], 5)\n",
    "            N_gram_mle_str[n][gram_str]=round(N_grams_cnt[n][gram]/N_grams_cnt[f\"{n}_total_cnt\"], 5)\n",
    "        else:\n",
    "            N_gram_mle[n][gram]=round(N_grams_cnt[n][gram]/tkn_n_gram_cnt, 5) # calcular MLE\n",
    "            N_gram_mle_str[n][gram_str]=round(N_grams_cnt[n][gram]/tkn_n_gram_cnt, 5) # calcular MLE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../outputs/n_gram_models.pkl\", \"wb\") as f:\n",
    "    pickle.dump(N_gram_mle_str, f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow-general-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
